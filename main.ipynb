{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from lightrag import LightRAG, QueryParam\n",
    "from lightrag.llm.openai import openai_complete_if_cache, openai_embed\n",
    "from lightrag.utils import EmbeddingFunc\n",
    "import numpy as np\n",
    "from lightrag.kg.shared_storage import initialize_pipeline_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = \"./amazon_product\"\n",
    "\n",
    "if not os.path.exists(WORKING_DIR):\n",
    "    os.mkdir(WORKING_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def llm_model_func(\n",
    "    prompt, system_prompt=None, history_messages=[], keyword_extraction=False, **kwargs\n",
    ") -> str:\n",
    "    return await openai_complete_if_cache(\n",
    "        os.getenv(\"LLM_MODEL\"),\n",
    "        prompt,\n",
    "        system_prompt=system_prompt,\n",
    "        history_messages=history_messages,\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "async def embedding_func(texts: list[str]) -> np.ndarray:\n",
    "    return await openai_embed(\n",
    "        texts,\n",
    "        model=os.getenv(\"EMBEDDING_MODEL\"),\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "    )\n",
    "\n",
    "\n",
    "async def get_embedding_dim():\n",
    "    test_text = [\"This is a test sentence.\"]\n",
    "    embedding = await embedding_func(test_text)\n",
    "    embedding_dim = embedding.shape[1]\n",
    "    return embedding_dim\n",
    "\n",
    "\n",
    "# function test\n",
    "async def test_funcs():\n",
    "    result = await llm_model_func(\"How are you?\")\n",
    "    print(\"llm_model_func: \", result)\n",
    "\n",
    "    result = await embedding_func([\"How are you?\"])\n",
    "    print(\"embedding_func: \", result)\n",
    "\n",
    "\n",
    "# asyncio.run(test_funcs())\n",
    "async def initialize_rag():\n",
    "    embedding_dimension = await get_embedding_dim()\n",
    "    print(f\"Detected embedding dimension: {embedding_dimension}\")\n",
    "\n",
    "    rag = LightRAG(\n",
    "        working_dir=WORKING_DIR,\n",
    "        llm_model_func=llm_model_func,\n",
    "        embedding_func=EmbeddingFunc(\n",
    "            embedding_dim=embedding_dimension,\n",
    "            max_token_size=8192,\n",
    "            func=embedding_func,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    await rag.initialize_storages()\n",
    "    await initialize_pipeline_status()\n",
    "\n",
    "    return rag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt = \"\"\"\n",
    "You are an expert assistant in web development and state management, specializing in mapping Redux-like state objects to corresponding DOM elements. \n",
    "Provide detailed and structured answers with practical examples that explain how specific state changes should trigger UI updates and endpoint modifications. \n",
    "\n",
    "---Conversation History--- \n",
    "{history} \n",
    "\n",
    "---Knowledge Base--- \n",
    "{context_data} \n",
    "\n",
    "---Response Rules---\n",
    "\n",
    "Target format and length: {response_type}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming initialize_rag, rag.aquery, and other relevant functions are defined earlier\n",
    "\n",
    "async def initialize_rag():\n",
    "    # Initialize your RAG instance (fill in this function with your actual code)\n",
    "    pass\n",
    "\n",
    "# Step 1: Initialize RAG\n",
    "rag = await initialize_rag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Read and insert the content from the HTML file\n",
    "with open(\"dataset/amazon_product.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "    await rag.ainsert(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Perform a local search\n",
    "local_search_result = await rag.aquery(\n",
    "    \"Retrieve all DOM elements and UI components associated with the state object key: selectedProduct. Identify which UI elements (e.g., icons, containers and endpoints) should be updated when this state key changes. Return a JSON object mapping the state object key: selectedProduct to an array of objects each detailing the line within the DOM, element's tag, relevant attributes, and inner text if applicable.\",\n",
    "    param=QueryParam(mode=\"local\"),\n",
    "    system_prompt=custom_prompt  # Pass the custom prompt\n",
    ")\n",
    "print(local_search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Perform a global search\n",
    "global_search_result = await rag.aquery(\n",
    "    \"Retrieve all DOM elements and UI components associated with the state object key: selectedProduct. Identify which UI elements (e.g., icons, containers) and endpoints should be updated when this state key changes, detailing the specific modifications required.\",\n",
    "    param=QueryParam(mode=\"global\"),\n",
    "    system_prompt=custom_prompt  # Pass the custom prompt\n",
    ")\n",
    "print(global_search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Perform a hybrid search\n",
    "hybrid_search_result = await rag.aquery(\n",
    "    \"Retrieve all DOM elements and UI components associated with the state object key: selectedProduct. Identify which UI elements (e.g., icons, containers and endpoints) should be updated when this state key changes. Return a JSON object mapping the state object key: selectedProduct to an array of objects each detailing the line within the DOM, element's tag, relevant attributes, and inner text if applicable.\",\n",
    "    param=QueryParam(mode=\"hybrid\"),\n",
    "    system_prompt=custom_prompt  # Pass the custom prompt\n",
    ")\n",
    "print(hybrid_search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
